This is an experiment that focuses on injecting long-term memories into LLM. The current problem with injecting memories via fine-tunning is that the model's behavior is often altered to fit the new data, sometimes to the point where it loses its capabilities. By using "dreaming", or generating data from memories using the model's own style, we should be able to inject memories with less alternation to the model.

### Progress
Heavily WIP