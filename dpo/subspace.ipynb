{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/dpo/env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9b61910a35149929d505ff2d1996be5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/dpo/env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id,\n",
    "    token = \"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\",\n",
    "    # attn_implementation=\"eager\" # so we can collect attentions\n",
    ").cuda()\n",
    "\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_id, token = \"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 4096)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_count = model.config.num_hidden_layers\n",
    "dim = model.config.hidden_size\n",
    "\n",
    "layer_count, dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "!echo $TRANSFORMERS_CACHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'url', 'title', 'text'],\n",
       "    num_rows: 1291734\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset, VerificationMode\n",
    "\n",
    "dataset = load_dataset(\"abokbot/wikipedia-first-paragraph\", data_files='data/train-00004-of-00005-36531985f2e6c8ce.parquet',split='train', verification_mode= VerificationMode.NO_CHECKS)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.filter(lambda x: len(x['text']) > 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62600"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[:5000]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Token Length Distribution')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkEAAAGzCAYAAAAotsMiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA8v0lEQVR4nO3df1hUdf7//8cgMP4cEBVGTZHQUvyRhamjtpaxklKbSbvpkoub1WZo+WPN3DUzK22t1HRRt65Wbct1c9+pZaYhmlbiL0pDLdPUMG3AT4aDpvw83z/6crYRLMWBAc/9dl3nupzX6zXnPF8vKB7XmXPO2AzDMAQAAGAxAf4uAAAAwB8IQQAAwJIIQQAAwJIIQQAAwJIIQQAAwJIIQQAAwJIIQQAAwJIIQQAAwJIIQQAAwJIIQUANYbPZNGrUKH+XUasdOXJENptNL7zwQrUdc/HixbLZbDpy5EiVH2v48OFq06aN+bq65zt16lTZbLZqORZQHQhBwGWw2WwXtX3wwQf+LvWS3HzzzerUqZO/y7igNWvWaOrUqT7f7wcffOD1c7Pb7YqIiNDNN9+s6dOn68SJEz45zg8//KCpU6fWyN+Lmlwb4GuB/i4AqM3+9a9/eb1+7bXXlJaWVq69Q4cO1VnWFW/NmjVKTU2tkiAkSY888ohuvPFGlZSU6MSJE9qyZYuefPJJzZo1S2+++ab69etnjh02bJiGDBkiu91+0fv/4Ycf9NRTT0n6MXBerFdeeUWlpaUXPb4yfq62yZMn6/HHH6/S4wPViRAEXIZ7773X6/XWrVuVlpZWrh21y0033aS7777bq2337t3q37+/EhMTtW/fPjVv3lySVKdOHdWpU6dK6zlz5owaNGigoKCgKj3OLwkMDFRgIH82cOXg4zCgip05c0bjx49Xq1atZLfbde211+qFF16QYRi/+N5nnnlGAQEBmjdvntn23nvv6aabblKDBg3UqFEjJSQkaO/evV7vGz58uBo2bKhjx45p0KBBatiwoZo1a6Y///nPKikp8dncfF3Ld999p2HDhsnhcCg0NFTJycnavXu3bDabFi9ebO4vNTVVkvfHked7+eWXFR0dLbvdrhtvvFE7duy4rLled911mjNnjvLy8vT3v//dbK/omqCdO3cqPj5eTZs2Vb169RQVFaX77rtP0o/X8TRr1kyS9NRTT5n1l53VKluvr776SgMHDlSjRo2UlJRk9v30mqCfmj17tiIjI1WvXj317dtXe/bs8eq/+eabKzzr9NN9/lJtFV0TVFxcrKefftpc6zZt2ugvf/mLCgoKvMa1adNGt99+uz766CN1795ddevW1dVXX63XXnut4gUHqgGRHqhChmHoN7/5jTZu3KgRI0aoa9euWrdunSZMmKBjx45p9uzZF3zv5MmTNX36dP3jH//QAw88IOnHj9+Sk5MVHx+vv/3tb/rhhx+0YMEC9enTR59++qnXH8iSkhLFx8erR48eeuGFF7R+/Xq9+OKLio6O1siRIy97br6upbS0VHfccYe2b9+ukSNHqn379lq1apWSk5O9jvunP/1Jx48fr/BjxzJLly5Vfn6+/vSnP8lms2nmzJkaPHiwDh06dFlnU+6++26NGDFC77//vp599tkKx+Tm5qp///5q1qyZHn/8cYWGhurIkSN66623JEnNmjXTggULNHLkSN11110aPHiwJKlLly7mPoqLixUfH68+ffrohRdeUP369X+2rtdee035+flKSUnRuXPn9NJLL6lfv37KyspSRETERc/vYmo73/33368lS5bo7rvv1vjx47Vt2zbNmDFDn3/+uVasWOE19uDBg+YaJicn65///KeGDx+u2NhYdezY8aLrBHzGAOAzKSkpxk//s1q5cqUhyXjmmWe8xt19992GzWYzDh48aLZJMlJSUgzDMIzx48cbAQEBxuLFi83+/Px8IzQ01HjggQe89uV2u42QkBCv9uTkZEOSMW3aNK+x119/vREbG/uL8+jbt6/RsWPHC/ZXRS3/93//Z0gy5syZY7aVlJQY/fr1MyQZixYtMtvPX+cyhw8fNiQZTZo0MU6ePGm2r1q1ypBkvPPOOz87740bNxqSjOXLl19wzHXXXWc0btzYfL1o0SJDknH48GHDMAxjxYoVhiRjx44dF9zHiRMnDEnGk08+Wa6vbL0ef/zxCvsiIyPN12XzrVevnvHNN9+Y7du2bTMkGWPHjjXb+vbta/Tt2/cX9/lztT355JNe675r1y5DknH//fd7jfvzn/9sSDI2bNhgtkVGRhqSjM2bN5ttubm5ht1uN8aPH1/uWEB14OMwoAqtWbNGderU0SOPPOLVPn78eBmGoffee8+r3TAMjRo1Si+99JJef/11r7MgaWlpysvL09ChQ/X//t//M7c6deqoR48e2rhxY7njP/TQQ16vb7rpJh06dOiy51UVtaxdu1ZBQUHmWS9JCggIUEpKyiXXd88996hx48Zex5Lkk7k3bNhQ+fn5F+wPDQ2VJK1evVpFRUWVPs6lnK0bNGiQWrZsab7u3r27evTooTVr1lT6+BejbP/jxo3zah8/frwk6d133/Vqj4mJMX8W0o9nnq699lqf/FyAyuDjMKAKff3112rRooUaNWrk1V52t9jXX3/t1f7aa6/p9OnTWrBggYYOHerVd+DAAUnyujPppxwOh9frunXrmtd3lGncuLG+//77S5/Ieaqilq+//lrNmzcv99FP27ZtL7m+1q1blzuWJJ/M/fTp0+V+nj/Vt29fJSYm6qmnntLs2bN18803a9CgQfr9739/0XeQBQYG6qqrrrromtq1a1eu7ZprrtGbb7550fuojK+//loBAQHlfkZOp1OhoaHlfr/P/7lIvvudBCqDEATUIL1799auXbv097//Xb/73e8UFhZm9pXdGv2vf/1LTqez3HvPv2unKu9Yqkm1VORCxzMu4mL0n1NUVKQvv/zyZ5+hZLPZ9N///ldbt27VO++8o3Xr1um+++7Tiy++qK1bt6phw4a/eBy73a6AAN+eqLfZbBXO3xcXyl/sAxSr6ucCVBYhCKhCkZGRWr9+vfLz873OHnzxxRdm/0+1bdtWM2fO1M0336zbbrtN6enp5vuio6MlSeHh4YqLi6umGVSsKmqJjIzUxo0b9cMPP3idDTp48GC5sf56avF///tfnT17VvHx8b84tmfPnurZs6eeffZZLV26VElJSVq2bJnuv/9+n9dfdmbup7788kuvi9MbN25c4cdO55+tuZTaIiMjVVpaqgMHDng9CysnJ0d5eXnlfr+BmoZrgoAqNHDgQJWUlHjdUi39eDuzzWbTgAEDyr2nS5cuWrNmjT7//HPdcccdOnv2rCQpPj5eDodD06dPr/BaE189zfhiVEUt8fHxKioq0iuvvGK2lZaWmrfD/1SDBg0kSXl5eZd8nMravXu3xowZo8aNG//sdUrff/99uTMbXbt2lSTztvGykOer+leuXKljx46Zr7dv365t27Z5/X5FR0friy++8PrZ7N69Wx9//LHXvi6ltoEDB0qS5syZ49U+a9YsSVJCQsIlzQOobpwJAqrQHXfcoVtuuUV//etfdeTIEV133XV6//33tWrVKo0ZM8Y8o3K+nj17atWqVRo4cKDuvvturVy5Ug6HQwsWLNCwYcN0ww03aMiQIWrWrJmys7P17rvvqnfv3uXC1uU4ceKEnnnmmXLtUVFRSkpK8nktgwYNUvfu3TV+/HgdPHhQ7du319tvv62TJ09K8j5DERsbK+nHJzvHx8erTp06GjJkyGXM1tuHH36oc+fOqaSkRN99950+/vhjvf322woJCdGKFSsq/AiwzJIlSzR//nzdddddio6OVn5+vl555RU5HA4zNNSrV08xMTH6z3/+o2uuuUZhYWHq1KlTpb+qpG3bturTp49GjhypgoICzZkzR02aNNFjjz1mjrnvvvs0a9YsxcfHa8SIEcrNzdXChQvVsWNHeTwec9yl1HbdddcpOTlZL7/8svLy8tS3b19t375dS5Ys0aBBg3TLLbdUaj5AtfHnrWnAlaaiW7fz8/ONsWPHGi1atDCCgoKMdu3aGc8//7xRWlrqNU4/uUW+zKpVq4zAwEDjnnvuMUpKSgzD+PE27vj4eCMkJMSoW7euER0dbQwfPtzYuXOn+b7k5GSjQYMG5eo7/xbnC+nbt68hqcLt1ltvNcf5upYTJ04Yv//9741GjRoZISEhxvDhw42PP/7YkGQsW7bMHFdcXGyMHj3aaNasmWGz2cz9lN0y/vzzz5c7ni5w2/dPld0iX7YFBQUZzZo1M371q18Zzz77rJGbm1vuPeffIv/JJ58YQ4cONVq3bm3Y7XYjPDzcuP32273WxDAMY8uWLUZsbKwRHBzsVduF1qusr6Jb5J9//nnjxRdfNFq1amXY7XbjpptuMnbv3l3u/a+//rpx9dVXG8HBwUbXrl2NdevWldvnz9VW0c+sqKjIeOqpp4yoqCgjKCjIaNWqlTFp0iTj3LlzXuMiIyONhISEcjVd6NZ9oDrYDIMr0gDUXCtXrtRdd92ljz76SL179/Z3OQCuIIQgADXG2bNnVa9ePfN1SUmJ+vfvr507d8rtdnv1AcDl4pogADXG6NGjdfbsWblcLhUUFOitt97Sli1bNH36dAIQAJ/jTBCAGmPp0qV68cUXdfDgQZ07d05t27bVyJEjNWrUKH+XBuAKRAgCAACWxHOCAACAJRGCAACAJXFhtH58Ku3x48fVqFEjvz2OHwAAXBrDMJSfn68WLVpU6vv2CEGSjh8/rlatWvm7DAAAUAlHjx7VVVdddcnvIwRJ5hdUHj16VA6Hw8/VAACAi+HxeNSqVSuvL6i+FIQg/e87iRwOByEIAIBaprKXsnBhNAAAsCRCEAAAsCRCEAAAsCRCEAAAsCS/hqA2bdrIZrOV21JSUiRJ586dU0pKipo0aaKGDRsqMTFROTk5XvvIzs5WQkKC6tevr/DwcE2YMEHFxcX+mA4AAKhF/BqCduzYoW+//dbc0tLSJEm//e1vJUljx47VO++8o+XLl2vTpk06fvy4Bg8ebL6/pKRECQkJKiws1JYtW7RkyRItXrxYU6ZM8ct8AABA7VGjvkB1zJgxWr16tQ4cOCCPx6NmzZpp6dKluvvuuyVJX3zxhTp06KCMjAz17NlT7733nm6//XYdP35cERERkqSFCxdq4sSJOnHihIKDgy/quB6PRyEhITp16hS3yAMAUEtc7t/vGnNNUGFhoV5//XXdd999stlsyszMVFFRkeLi4swx7du3V+vWrZWRkSFJysjIUOfOnc0AJEnx8fHyeDzau3fvBY9VUFAgj8fjtQEAAGupMSFo5cqVysvL0/DhwyVJbrdbwcHBCg0N9RoXEREht9ttjvlpACrrL+u7kBkzZigkJMTc+MoMAACsp8aEoFdffVUDBgxQixYtqvxYkyZN0qlTp8zt6NGjVX5MAABQs9SIr834+uuvtX79er311ltmm9PpVGFhofLy8rzOBuXk5MjpdJpjtm/f7rWvsrvHysZUxG63y263+3AGAACgtqkRZ4IWLVqk8PBwJSQkmG2xsbEKCgpSenq62bZ//35lZ2fL5XJJklwul7KyspSbm2uOSUtLk8PhUExMTPVNAAAA1Dp+PxNUWlqqRYsWKTk5WYGB/ysnJCREI0aM0Lhx4xQWFiaHw6HRo0fL5XKpZ8+ekqT+/fsrJiZGw4YN08yZM+V2uzV58mSlpKRwpgcAAPwsv4eg9evXKzs7W/fdd1+5vtmzZysgIECJiYkqKChQfHy85s+fb/bXqVNHq1ev1siRI+VyudSgQQMlJydr2rRp1TmFKldQUKDMzMxy7bGxsYQ9AAAqqUY9J8hfavpzgrZs2aJH5q9SaMtosy3v2Fea+/Cd6tWrlx8rAwDAfy7377ffzwTh4oS2jFbT6M7+LgMAgCtGjbgwGgAAoLoRggAAgCXxcVgtVVpcpKysLK82LpQGAODiEYJqKU9OtuYdOSvnIZuksgulxYXSAABcJEJQLdbIGcXF0gAAVBLXBAEAAEsiBAEAAEsiBAEAAEsiBAEAAEsiBAEAAEsiBAEAAEsiBAEAAEsiBAEAAEsiBAEAAEsiBAEAAEsiBAEAAEsiBAEAAEsiBAEAAEsiBAEAAEsiBAEAAEsiBAEAAEsiBAEAAEsiBAEAAEsiBAEAAEsiBAEAAEsiBAEAAEsiBAEAAEsiBAEAAEsiBAEAAEsiBAEAAEsiBAEAAEsiBAEAAEsiBAEAAEsiBAEAAEsiBAEAAEsiBAEAAEsiBAEAAEsiBAEAAEsiBAEAAEvyewg6duyY7r33XjVp0kT16tVT586dtXPnTrPfMAxNmTJFzZs3V7169RQXF6cDBw547ePkyZNKSkqSw+FQaGioRowYodOnT1f3VAAAQC3i1xD0/fffq3fv3goKCtJ7772nffv26cUXX1Tjxo3NMTNnztTcuXO1cOFCbdu2TQ0aNFB8fLzOnTtnjklKStLevXuVlpam1atXa/PmzXrwwQf9MSUAAFBLBPrz4H/729/UqlUrLVq0yGyLiooy/20YhubMmaPJkyfrzjvvlCS99tprioiI0MqVKzVkyBB9/vnnWrt2rXbs2KFu3bpJkubNm6eBAwfqhRdeUIsWLap3UgAAoFbw65mgt99+W926ddNvf/tbhYeH6/rrr9crr7xi9h8+fFhut1txcXFmW0hIiHr06KGMjAxJUkZGhkJDQ80AJElxcXEKCAjQtm3bKjxuQUGBPB6P1wYAAKzFryHo0KFDWrBggdq1a6d169Zp5MiReuSRR7RkyRJJktvtliRFRER4vS8iIsLsc7vdCg8P9+oPDAxUWFiYOeZ8M2bMUEhIiLm1atXK11MDAAA1nF9DUGlpqW644QZNnz5d119/vR588EE98MADWrhwYZUed9KkSTp16pS5HT16tEqPBwAAah6/hqDmzZsrJibGq61Dhw7Kzs6WJDmdTklSTk6O15icnByzz+l0Kjc316u/uLhYJ0+eNMecz263y+FweG0AAMBa/HphdO/evbV//36vti+//FKRkZGSfrxI2ul0Kj09XV27dpUkeTwebdu2TSNHjpQkuVwu5eXlKTMzU7GxsZKkDRs2qLS0VD169Ki+yfhZaXGRsrKyyrXHxsbKbrf7oSIAAGo2v4agsWPHqlevXpo+fbp+97vfafv27Xr55Zf18ssvS5JsNpvGjBmjZ555Ru3atVNUVJSeeOIJtWjRQoMGDZL045mj2267zfwYraioSKNGjdKQIUMsdWeYJydb846clfOQzWzLO/aV5j4s9erVy4+VAQBQM/k1BN14441asWKFJk2apGnTpikqKkpz5sxRUlKSOeaxxx7TmTNn9OCDDyovL099+vTR2rVrVbduXXPMG2+8oVGjRunWW29VQECAEhMTNXfuXH9Mya8aOaPUNLqzv8sAAKBW8GsIkqTbb79dt99++wX7bTabpk2bpmnTpl1wTFhYmJYuXVoV5flFQUGBMjMzzddZWVkqLfVjQQAAXIH8HoJQXmZmph6Zv0qhLaMlSd/s+lCN28b6uSoAAK4shKAaKrRltPnRVt6xr/xcDQAAVx6/f4EqAACAPxCCAACAJRGCAACAJRGCAACAJRGCAACAJRGCAACAJRGCAACAJRGCAACAJRGCAACAJRGCAACAJRGCAACAJRGCAACAJRGCAACAJRGCAACAJRGCAACAJRGCAACAJRGCAACAJRGCAACAJRGCAACAJRGCAACAJRGCAACAJRGCAACAJRGCAACAJRGCAACAJRGCAACAJRGCAACAJRGCAACAJRGCAACAJRGCAACAJRGCAACAJRGCAACAJRGCAACAJRGCAACAJRGCAACAJRGCAACAJRGCAACAJRGCAACAJRGCAACAJfk1BE2dOlU2m81ra9++vdl/7tw5paSkqEmTJmrYsKESExOVk5PjtY/s7GwlJCSofv36Cg8P14QJE1RcXFzdUwEAALVMoL8L6Nixo9avX2++Dgz8X0ljx47Vu+++q+XLlyskJESjRo3S4MGD9fHHH0uSSkpKlJCQIKfTqS1btujbb7/VH/7wBwUFBWn69OnVPhcAAFB7+D0EBQYGyul0lms/deqUXn31VS1dulT9+vWTJC1atEgdOnTQ1q1b1bNnT73//vvat2+f1q9fr4iICHXt2lVPP/20Jk6cqKlTpyo4OLi6pwMAAGoJv18TdODAAbVo0UJXX321kpKSlJ2dLUnKzMxUUVGR4uLizLHt27dX69atlZGRIUnKyMhQ586dFRERYY6Jj4+Xx+PR3r17L3jMgoICeTwerw0AAFiLX0NQjx49tHjxYq1du1YLFizQ4cOHddNNNyk/P19ut1vBwcEKDQ31ek9ERITcbrckye12ewWgsv6yvguZMWOGQkJCzK1Vq1a+nRgAAKjx/Ppx2IABA8x/d+nSRT169FBkZKTefPNN1atXr8qOO2nSJI0bN8587fF4CEIAAFiM3z8O+6nQ0FBdc801OnjwoJxOpwoLC5WXl+c1Jicnx7yGyOl0lrtbrOx1RdcZlbHb7XI4HF4bAACwlhoVgk6fPq2vvvpKzZs3V2xsrIKCgpSenm7279+/X9nZ2XK5XJIkl8ulrKws5ebmmmPS0tLkcDgUExNT7fUDAIDaw68fh/35z3/WHXfcocjISB0/flxPPvmk6tSpo6FDhyokJEQjRozQuHHjFBYWJofDodGjR8vlcqlnz56SpP79+ysmJkbDhg3TzJkz5Xa7NXnyZKWkpMhut/tzagAAoIbzawj65ptvNHToUH333Xdq1qyZ+vTpo61bt6pZs2aSpNmzZysgIECJiYkqKChQfHy85s+fb76/Tp06Wr16tUaOHCmXy6UGDRooOTlZ06ZN89eUAABALeHXELRs2bKf7a9bt65SU1OVmpp6wTGRkZFas2aNr0sDAABXuBp1TRAAAEB1IQQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLCvR3Aag6pcVFysrK8mqLjY2V3W73U0UAANQchKArmCcnW/OOnJXzkE2SlHfsK819WOrVq5efKwMAwP8IQVe4Rs4oNY3u7O8yAACocbgmCAAAWFKNCUHPPfecbDabxowZY7adO3dOKSkpatKkiRo2bKjExETl5OR4vS87O1sJCQmqX7++wsPDNWHCBBUXF1dz9QAAoLapESFox44d+sc//qEuXbp4tY8dO1bvvPOOli9frk2bNun48eMaPHiw2V9SUqKEhAQVFhZqy5YtWrJkiRYvXqwpU6ZU9xQAAEAt4/cQdPr0aSUlJemVV15R48aNzfZTp07p1Vdf1axZs9SvXz/FxsZq0aJF2rJli7Zu3SpJev/997Vv3z69/vrr6tq1qwYMGKCnn35aqampKiws9NeUAABALeD3EJSSkqKEhATFxcV5tWdmZqqoqMirvX379mrdurUyMjIkSRkZGercubMiIiLMMfHx8fJ4PNq7d+8Fj1lQUCCPx+O1AQAAa/Hr3WHLli3TJ598oh07dpTrc7vdCg4OVmhoqFd7RESE3G63OeanAaisv6zvQmbMmKGnnnrqMqsHAAC1md/OBB09elSPPvqo3njjDdWtW7dajz1p0iSdOnXK3I4ePVqtxwcAAP7ntxCUmZmp3Nxc3XDDDQoMDFRgYKA2bdqkuXPnKjAwUBERESosLFReXp7X+3JycuR0OiVJTqez3N1iZa/LxlTEbrfL4XB4bQAAwFoqFYKuvvpqfffdd+Xa8/LydPXVV1/UPm699VZlZWVp165d5tatWzclJSWZ/w4KClJ6err5nv379ys7O1sul0uS5HK5lJWVpdzcXHNMWlqaHA6HYmJiKjM1AABgEZW6JujIkSMqKSkp115QUKBjx45d1D4aNWqkTp06ebU1aNBATZo0MdtHjBihcePGKSwsTA6HQ6NHj5bL5VLPnj0lSf3791dMTIyGDRummTNnyu12a/LkyUpJSeH7sQAAwM+6pBD09ttvm/9et26dQkJCzNclJSVKT09XmzZtfFbc7NmzFRAQoMTERBUUFCg+Pl7z5883++vUqaPVq1dr5MiRcrlcatCggZKTkzVt2jSf1QAAAK5MlxSCBg0aJEmy2WxKTk726gsKClKbNm304osvVrqYDz74wOt13bp1lZqaqtTU1Au+JzIyUmvWrKn0MQEAgDVdUggqLS2VJEVFRWnHjh1q2rRplRQFAABQ1Sp1TdDhw4d9XQcAAEC1qvTDEtPT05Wenq7c3FzzDFGZf/7zn5ddGAAAQFWqVAh66qmnNG3aNHXr1k3NmzeXzWbzdV0AAABVqlIhaOHChVq8eLGGDRvm63oAAACqRaUellhYWKhevXr5uhYAAIBqU6kQdP/992vp0qW+rgUAAKDaVOrjsHPnzunll1/W+vXr1aVLFwUFBXn1z5o1yyfFAQAAVJVKhaDPPvtMXbt2lSTt2bPHq4+LpAEAQG1QqRC0ceNGX9cBAABQrSp1TRAAAEBtV6kzQbfccsvPfuy1YcOGShcEAABQHSoVgsquBypTVFSkXbt2ac+ePeW+WBUAAKAmqlQImj17doXtU6dO1enTpy+rIAAAgOpQ6e8Oq8i9996r7t2764UXXvDlbq9oBQUFyszM9GrLysrSeV/HBgAAfMynISgjI0N169b15S6veJmZmXpk/iqFtow2277Z9aEat431Y1UAAFz5KhWCBg8e7PXaMAx9++232rlzp5544gmfFGYloS2j1TS6s/k679hXfqwGAABrqFQICgkJ8XodEBCga6+9VtOmTVP//v19UhgAAEBVqlQIWrRoka/rAAAAqFaXdU1QZmamPv/8c0lSx44ddf311/ukKAAAgKpWqRCUm5urIUOG6IMPPlBoaKgkKS8vT7fccouWLVumZs2a+bJGAAAAn6vU12aMHj1a+fn52rt3r06ePKmTJ09qz5498ng8euSRR3xdIwAAgM9V6kzQ2rVrtX79enXo0MFsi4mJUWpqKhdG12ClxUXKysoq1x4bGyu73e6HigAA8J9KhaDS0lIFBQWVaw8KClIpT/mrsTw52Zp35Kych/73vW95x77S3IelXr16+bEyAACqX6VCUL9+/fToo4/q3//+t1q0aCFJOnbsmMaOHatbb73VpwXCtxo5o7yeSQQAgFVV6pqgv//97/J4PGrTpo2io6MVHR2tqKgoeTwezZs3z9c1AgAA+FylzgS1atVKn3zyidavX68vvvhCktShQwfFxcX5tDgAAICqcklngjZs2KCYmBh5PB7ZbDb9+te/1ujRozV69GjdeOON6tixoz788MOqqhUAAMBnLikEzZkzRw888IAcDke5vpCQEP3pT3/SrFmzfFYcAABAVbmkELR7927ddtttF+zv37+/MjMzL7soAACAqnZJISgnJ6fCW+PLBAYG6sSJE5ddFAAAQFW7pBDUsmVL7dmz54L9n332mZo3b37ZRQEAAFS1SwpBAwcO1BNPPKFz586V6zt79qyefPJJ3X777T4rDgAAoKpc0i3ykydP1ltvvaVrrrlGo0aN0rXXXitJ+uKLL5SamqqSkhL99a9/rZJCAQAAfOmSQlBERIS2bNmikSNHatKkSTIMQ5Jks9kUHx+v1NRURUREVEmhAAAAvnTJD0uMjIzUmjVr9P333+vgwYMyDEPt2rVT48aNq6I+AACAKlGpJ0ZLUuPGjXXjjTf6shYAAIBqU6nvDgMAAKjtCEEAAMCSCEEAAMCSCEEAAMCS/BqCFixYoC5dusjhcMjhcMjlcum9994z+8+dO6eUlBQ1adJEDRs2VGJionJycrz2kZ2drYSEBNWvX1/h4eGaMGGCiouLq3sqAACglvFrCLrqqqv03HPPKTMzUzt37lS/fv105513au/evZKksWPH6p133tHy5cu1adMmHT9+XIMHDzbfX1JSooSEBBUWFmrLli1asmSJFi9erClTpvhrSgAAoJao9C3yvnDHHXd4vX722We1YMECbd26VVdddZVeffVVLV26VP369ZMkLVq0SB06dNDWrVvVs2dPvf/++9q3b5/Wr1+viIgIde3aVU8//bQmTpyoqVOnKjg42B/TAgAAtUCNuSaopKREy5Yt05kzZ+RyuZSZmamioiLFxcWZY9q3b6/WrVsrIyNDkpSRkaHOnTt7PaU6Pj5eHo/HPJtUkYKCAnk8Hq8NAABYi99DUFZWlho2bCi73a6HHnpIK1asUExMjNxut4KDgxUaGuo1PiIiQm63W5LkdrvLfU1H2euyMRWZMWOGQkJCzK1Vq1a+nRQAAKjx/B6Crr32Wu3atUvbtm3TyJEjlZycrH379lXpMSdNmqRTp06Z29GjR6v0eAAAoObx6zVBkhQcHKy2bdtKkmJjY7Vjxw699NJLuueee1RYWKi8vDyvs0E5OTlyOp2SJKfTqe3bt3vtr+zusbIxFbHb7bLb7T6eCQAAqE38fibofKWlpSooKFBsbKyCgoKUnp5u9u3fv1/Z2dlyuVySJJfLpaysLOXm5ppj0tLS5HA4FBMTU+21AwCA2sOvZ4ImTZqkAQMGqHXr1srPz9fSpUv1wQcfaN26dQoJCdGIESM0btw4hYWFyeFwaPTo0XK5XOrZs6ckqX///oqJidGwYcM0c+ZMud1uTZ48WSkpKZzpAQAAP8uvISg3N1d/+MMf9O233yokJERdunTRunXr9Otf/1qSNHv2bAUEBCgxMVEFBQWKj4/X/PnzzffXqVNHq1ev1siRI+VyudSgQQMlJydr2rRp/poSAACoJfwagl599dWf7a9bt65SU1OVmpp6wTGRkZFas2aNr0sDAABXuBp3TRAAAEB1IAQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLCvR3AfCv0uIiZWVlebXFxsbKbrf7qSIAAKoHIcjiPDnZmnfkrJyHbJKkvGNfae7DUq9evfxcGQAAVYsQBDVyRqlpdGd/lwEAQLXimiAAAGBJhCAAAGBJhCAAAGBJhCAAAGBJhCAAAGBJhCAAAGBJhCAAAGBJhCAAAGBJhCAAAGBJhCAAAGBJhCAAAGBJhCAAAGBJhCAAAGBJhCAAAGBJhCAAAGBJhCAAAGBJhCAAAGBJhCAAAGBJhCAAAGBJhCAAAGBJhCAAAGBJfg1BM2bM0I033qhGjRopPDxcgwYN0v79+73GnDt3TikpKWrSpIkaNmyoxMRE5eTkeI3Jzs5WQkKC6tevr/DwcE2YMEHFxcXVORUAAFDL+DUEbdq0SSkpKdq6davS0tJUVFSk/v3768yZM+aYsWPH6p133tHy5cu1adMmHT9+XIMHDzb7S0pKlJCQoMLCQm3ZskVLlizR4sWLNWXKFH9MCQAA1BKB/jz42rVrvV4vXrxY4eHhyszM1K9+9SudOnVKr776qpYuXap+/fpJkhYtWqQOHTpo69at6tmzp95//33t27dP69evV0REhLp27aqnn35aEydO1NSpUxUcHOyPqQEAgBquRl0TdOrUKUlSWFiYJCkzM1NFRUWKi4szx7Rv316tW7dWRkaGJCkjI0OdO3dWRESEOSY+Pl4ej0d79+6t8DgFBQXyeDxeGwAAsJYaE4JKS0s1ZswY9e7dW506dZIkud1uBQcHKzQ01GtsRESE3G63OeanAaisv6yvIjNmzFBISIi5tWrVysezAQAANZ1fPw77qZSUFO3Zs0cfffRRlR9r0qRJGjdunPna4/EQhP5/pcVFysrKKtceGxsru93uh4oAAKgaNSIEjRo1SqtXr9bmzZt11VVXme1Op1OFhYXKy8vzOhuUk5Mjp9Npjtm+fbvX/sruHisbcz673c4f9Avw5GRr3pGzch6ymW15x77S3IelXr16+bEyAAB8y68fhxmGoVGjRmnFihXasGGDoqKivPpjY2MVFBSk9PR0s23//v3Kzs6Wy+WSJLlcLmVlZSk3N9cck5aWJofDoZiYmOqZyBWmkTNKTaM7m1toy2h/lwQAgM/59UxQSkqKli5dqlWrVqlRo0bmNTwhISGqV6+eQkJCNGLECI0bN05hYWFyOBwaPXq0XC6XevbsKUnq37+/YmJiNGzYMM2cOVNut1uTJ09WSkoKZ3sAAMAF+TUELViwQJJ08803e7UvWrRIw4cPlyTNnj1bAQEBSkxMVEFBgeLj4zV//nxzbJ06dbR69WqNHDlSLpdLDRo0UHJysqZNm1Zd0wAAALWQX0OQYRi/OKZu3bpKTU1VamrqBcdERkZqzZo1viwNAABc4WrMLfIAAADViRAEAAAsiRAEAAAsiRAEAAAsiRAEAAAsiRAEAAAsiRAEAAAsiRAEAAAsiRAEAAAsiRAEAAAsiRAEAAAsiRAEAAAsiRAEAAAsiRAEAAAsiRAEAAAsiRAEAAAsiRAEAAAsKdDfBaDmKy0uUlZWlldbbGys7Ha7nyoCAODyEYLwizw52Zp35Kych2ySpLxjX2nuw1KvXr38XBkAAJVHCMJFaeSMUtPozv4uAwAAn+GaIAAAYEmEIAAAYEmEIAAAYEmEIAAAYEmEIAAAYEmEIAAAYEmEIAAAYEmEIAAAYEmEIAAAYEmEIAAAYEmEIAAAYEmEIAAAYEmEIAAAYEl8i3w1KygoUGZmpvk6KytLpaV+LAgAAIsiBFWzzMxMPTJ/lUJbRkuSvtn1oRq3jfVzVQAAWA8hyA9CW0araXRnSVLesa/8XA0AANZECMIlKy0uUlZWVrn22NhY2e12P1QEAMClIwThknlysjXvyFk5D9nMtrxjX2nuw1KvXr38WBkAABePEIRKaeSMMj/SAwCgNuIWeQAAYEl+DUGbN2/WHXfcoRYtWshms2nlypVe/YZhaMqUKWrevLnq1aunuLg4HThwwGvMyZMnlZSUJIfDodDQUI0YMUKnT5+uxlkAAIDayK8h6MyZM7ruuuuUmppaYf/MmTM1d+5cLVy4UNu2bVODBg0UHx+vc+fOmWOSkpK0d+9epaWlafXq1dq8ebMefPDB6poCAACopfx6TdCAAQM0YMCACvsMw9CcOXM0efJk3XnnnZKk1157TREREVq5cqWGDBmizz//XGvXrtWOHTvUrVs3SdK8efM0cOBAvfDCC2rRokW1zQUAANQuNfaaoMOHD8vtdisuLs5sCwkJUY8ePZSRkSFJysjIUGhoqBmAJCkuLk4BAQHatm3bBfddUFAgj8fjtQEAAGupsSHI7XZLkiIiIrzaIyIizD63263w8HCv/sDAQIWFhZljKjJjxgyFhISYW6tWrXxcPQAAqOlqbAiqSpMmTdKpU6fM7ejRo/4uCQAAVLMaG4KcTqckKScnx6s9JyfH7HM6ncrNzfXqLy4u1smTJ80xFbHb7XI4HF4bAACwlhobgqKiouR0OpWenm62eTwebdu2TS6XS5LkcrmUl5fn9a3sGzZsUGlpqXr06FHtNQMAgNrDr3eHnT59WgcPHjRfHz58WLt27VJYWJhat26tMWPG6JlnnlG7du0UFRWlJ554Qi1atNCgQYMkSR06dNBtt92mBx54QAsXLlRRUZFGjRqlIUOGcGdYNavo+8T4LjEAQE3m1xC0c+dO3XLLLebrcePGSZKSk5O1ePFiPfbYYzpz5owefPBB5eXlqU+fPlq7dq3q1q1rvueNN97QqFGjdOuttyogIECJiYmaO3dutc/F6s7/PjG+SwwAUNP5NQTdfPPNMgzjgv02m03Tpk3TtGnTLjgmLCxMS5curYrycIn4PjEAQG1SY68JAgAAqEqEIAAAYEmEIAAAYEmEIAAAYEmEIAAAYEmEIAAAYEl+vUUeV66KHp5YWFgoSQoODjbbeKAiAMBfCEGoEuc/PFGSvtm1WYENw+Rs20kSD1QEAPgXIQhV5vyHJ+Yd+0pBIU4eqAgAqBG4JggAAFgSIQgAAFgSIQgAAFgSIQgAAFgSIQgAAFgSIQgAAFgSIQgAAFgSIQgAAFgSIQgAAFgSIQgAAFgSIQgAAFgSIQgAAFgSIQgAAFgSIQgAAFgSIQgAAFhSoL8LgHWVFhcpKyurXHtsbKzsdrsfKgIAWAkhCH7jycnWvCNn5TxkM9vyjn2luQ9LvXr18mNlAAArIATBrxo5o9Q0urO/ywAAWBDXBAEAAEviTBBqtIKCAmVmZpZr57ohAMDlIgRVoYr+gGdlZam01E8F1UKZmZl6ZP4qhbaMNtu4bggA4AuEoCpU0R/wb3Z9qMZtY/1YVe0T2jKa64YAAD5HCKpi5/8Bzzv2lR+ruTJUdGs9H48BAC4VIQi1zvm31vPxGACgMghBqFHOP8tzoWuouLUeAHC5CEGoUc4/y3Mx11Dx5GkAQGUQglDj/PQsz8VcQ8WTpwEAlUEIwhXh/I/HuHgaAPBLCEG4Ip1/duhk9n796eYsde7sfR3RLwWjip71RJgCgCsDIQhXrPM/Vpv3/l6vj8wqCkbnB5zzn/Xkq4/ZeBI2APgfIQiWcf5HZucHo4pCUVZWlhzNrzbf56uLsHkSNgD43xUTglJTU/X888/L7Xbruuuu07x589S9e3d/l4Ua7pfOFp1/d5ovL8LmSdgA4F9XRAj6z3/+o3HjxmnhwoXq0aOH5syZo/j4eO3fv1/h4eH+Lg+1SEVni35pzPlnhwoLCyVJwcHBF2y7mO+Q4yMzAKhaV0QImjVrlh544AH98Y9/lCQtXLhQ7777rv75z3/q8ccf93N1uNKVf7bRZgU2DJOzbSdzzPltF/P8o4o+MqvoI7vzA9bFhLCKxkjeAauiEFbR+whlAGqrWh+CCgsLlZmZqUmTJpltAQEBiouLU0ZGRoXvKSgoUEFBgfn61KlTkiSPx+PT2s6cOaPvjuxTccHZ/x3r2yMK9JySPSigwteMqaVjGjQ2f84lxUWyFRV6/dzPbyspLlLe0f3n7eewtm//QWfOnJEk7d27VyVFBV77yc/9Rs/8c59CnZ+Ybd8d2ac6dRsq1Nm6wtcXO+aHk26NTrxFHTt2NI8/7/82qn6Y84L7Of89AFCRHj16VMl+y/5uG4ZRuR0YtdyxY8cMScaWLVu82idMmGB07969wvc8+eSThiQ2NjY2Nja2K2A7evRopTJErT8TVBmTJk3SuHHjzNelpaU6efKkmjRpIpvN9jPvvDJ5PB61atVKR48elcPh8Hc5tR7r6Vusp2+xnr7FevrWpa6nYRjKz89XixYtKnW8Wh+CmjZtqjp16ignJ8erPScnR06ns8L32O32ctcwhIaGVlWJtYbD4eA/Yh9iPX2L9fQt1tO3WE/fupT1DAkJqfRxAn55SM0WHBys2NhYpaenm22lpaVKT0+Xy+XyY2UAAKAmq/VngiRp3LhxSk5OVrdu3dS9e3fNmTNHZ86cMe8WAwAAON8VEYLuuecenThxQlOmTJHb7VbXrl21du1aRURE+Lu0WsFut+vJJ5/kNmcfYT19i/X0LdbTt1hP36ru9bQZRmXvKwMAAKi9av01QQAAAJVBCAIAAJZECAIAAJZECAIAAJZECAIAAJZECLpCzZgxQzfeeKMaNWqk8PBwDRo0SPv37/cac+7cOaWkpKhJkyZq2LChEhMTyz15Ozs7WwkJCapfv77Cw8M1YcIEFRcXV+dUaqTnnntONptNY8aMMdtYz0tz7Ngx3XvvvWrSpInq1aunzp07a+fOnWa/YRiaMmWKmjdvrnr16ikuLk4HDhzw2sfJkyeVlJQkh8Oh0NBQjRgxQqdPn67uqfhdSUmJnnjiCUVFRalevXqKjo7W008/7fWlkqznhW3evFl33HGHWrRoIZvNppUrV3r1+2rtPvvsM910002qW7euWrVqpZkzZ1b11Pzi59azqKhIEydOVOfOndWgQQO1aNFCf/jDH3T8+HGvfVTbelbqG8dQ48XHxxuLFi0y9uzZY+zatcsYOHCg0bp1a+P06dPmmIceesho1aqVkZ6ebuzcudPo2bOn0atXL7O/uLjY6NSpkxEXF2d8+umnxpo1a4ymTZsakyZN8seUaozt27cbbdq0Mbp06WI8+uijZjvrefFOnjxpREZGGsOHDze2bdtmHDp0yFi3bp1x8OBBc8xzzz1nhISEGCtXrjR2795t/OY3vzGioqKMs2fPmmNuu+0247rrrjO2bt1qfPjhh0bbtm2NoUOH+mNKfvXss88aTZo0MVavXm0cPnzYWL58udGwYUPjpZdeMsewnhe2Zs0a469//avx1ltvGZKMFStWePX7Yu1OnTplREREGElJScaePXuMf//730a9evWMf/zjH9U1zWrzc+uZl5dnxMXFGf/5z3+ML774wsjIyDC6d+9uxMbGeu2jutaTEGQRubm5hiRj06ZNhmH8+IsYFBRkLF++3Bzz+eefG5KMjIwMwzB+/EUOCAgw3G63OWbBggWGw+EwCgoKqncCNUR+fr7Rrl07Iy0tzejbt68ZgljPSzNx4kSjT58+F+wvLS01nE6n8fzzz5tteXl5ht1uN/79738bhmEY+/btMyQZO3bsMMe89957hs1mM44dO1Z1xddACQkJxn333efVNnjwYCMpKckwDNbzUpz/R9tXazd//nyjcePGXv+tT5w40bj22mureEb+VVGoPN/27dsNScbXX39tGEb1ricfh1nEqVOnJElhYWGSpMzMTBUVFSkuLs4c0759e7Vu3VoZGRmSpIyMDHXu3Nnrydvx8fHyeDzau3dvNVZfc6SkpCghIcFr3STW81K9/fbb6tatm377298qPDxc119/vV555RWz//Dhw3K73V7rGRISoh49enitZ2hoqLp162aOiYuLU0BAgLZt21Z9k6kBevXqpfT0dH355ZeSpN27d+ujjz7SgAEDJLGel8NXa5eRkaFf/epXCg4ONsfEx8dr//79+v7776tpNjXTqVOnZLPZzC8yr871vCK+NgM/r7S0VGPGjFHv3r3VqVMnSZLb7VZwcLD5S1cmIiJCbrfbHHP+V4+UvS4bYyXLli3TJ598oh07dpTrYz0vzaFDh7RgwQKNGzdOf/nLX7Rjxw498sgjCg4OVnJysrkeFa3XT9czPDzcqz8wMFBhYWGWW8/HH39cHo9H7du3V506dVRSUqJnn31WSUlJksR6XgZfrZ3b7VZUVFS5fZT1NW7cuErqr+nOnTuniRMnaujQoea3xlfnehKCLCAlJUV79uzRRx995O9Saq2jR4/q0UcfVVpamurWrevvcmq90tJSdevWTdOnT5ckXX/99dqzZ48WLlyo5ORkP1dX+7z55pt64403tHTpUnXs2FG7du3SmDFj1KJFC9YTNVZRUZF+97vfyTAMLViwwC818HHYFW7UqFFavXq1Nm7cqKuuuspsdzqdKiwsVF5entf4nJwcOZ1Oc8z5dzeVvS4bYxWZmZnKzc3VDTfcoMDAQAUGBmrTpk2aO3euAgMDFRERwXpegubNmysmJsarrUOHDsrOzpb0v/WoaL1+up65uble/cXFxTp58qTl1nPChAl6/PHHNWTIEHXu3FnDhg3T2LFjNWPGDEms5+Xw1drx37+3sgD09ddfKy0tzTwLJFXvehKCrlCGYWjUqFFasWKFNmzYUO60YWxsrIKCgpSenm627d+/X9nZ2XK5XJIkl8ulrKwsr1/Gsl/W8/+AXeluvfVWZWVladeuXebWrVs3JSUlmf9mPS9e7969yz2y4csvv1RkZKQkKSoqSk6n02s9PR6Ptm3b5rWeeXl5yszMNMds2LBBpaWl6tGjRzXMoub44YcfFBDg/b/zOnXqqLS0VBLreTl8tXYul0ubN29WUVGROSYtLU3XXnut5T4KKwtABw4c0Pr169WkSROv/mpdz0u6jBq1xsiRI42QkBDjgw8+ML799ltz++GHH8wxDz30kNG6dWtjw4YNxs6dOw2Xy2W4XC6zv+yW7v79+xu7du0y1q5dazRr1sySt3RX5Kd3hxkG63kptm/fbgQGBhrPPvusceDAAeONN94w6tevb7z++uvmmOeee84IDQ01Vq1aZXz22WfGnXfeWeFtyddff72xbds246OPPjLatWtniVu6z5ecnGy0bNnSvEX+rbfeMpo2bWo89thj5hjW88Ly8/ONTz/91Pj0008NScasWbOMTz/91LxbyRdrl5eXZ0RERBjDhg0z9uzZYyxbtsyoX7/+FXmL/M+tZ2FhofGb3/zGuOqqq4xdu3Z5/X366Z1e1bWehKArlKQKt0WLFpljzp49azz88MNG48aNjfr16xt33XWX8e2333rt58iRI8aAAQOMevXqGU2bNjXGjx9vFBUVVfNsaqbzQxDreWneeecdo1OnTobdbjfat29vvPzyy179paWlxhNPPGFEREQYdrvduPXWW439+/d7jfnuu++MoUOHGg0bNjQcDofxxz/+0cjPz6/OadQIHo/HePTRR43WrVsbdevWNa6++mrjr3/9q9cfFdbzwjZu3Fjh/y+Tk5MNw/Dd2u3evdvo06ePYbfbjZYtWxrPPfdcdU2xWv3ceh4+fPiCf582btxo7qO61tNmGD95pCgAAIBFcE0QAACwJEIQAACwJEIQAACwJEIQAACwJEIQAACwJEIQAACwJEIQAACwJEIQAACwJEIQAACwJEIQAACwJEIQAACwpP8PIpILBgxuS0YAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "text_tokens_length = np.array([len(tokenizer.encode(text)) for text in dataset])\n",
    "\n",
    "sns.histplot(text_tokens_length, bins=100)\n",
    "sns.set_theme()\n",
    "plt.title(\"Token Length Distribution\")\n",
    "\n",
    "# get top 10 indices\n",
    "# process_count = 50\n",
    "# top_indices = np.argsort(text_tokens_length)[-process_count:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('/workspace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# importlib.reload(sys.modules['llm_wizard.util.prompt'])\n",
    "\n",
    "from llm_wizard.util.prompt import ChatTemplates, SystemTemplate, UserTemplate, AssistantTemplate, ChatTokenizer\n",
    "\n",
    "templates = ChatTemplates(templates=[\n",
    "    SystemTemplate(template=\"You are a helpful assistant.\"),\n",
    "    UserTemplate(template=\"Summarize the following paragraph: {paragraph}\"),\n",
    "    AssistantTemplate(template=\"\"\"Sure! This paragraph is about \"\"\"),\n",
    "])\n",
    "\n",
    "chat_tokenizer = ChatTokenizer(tokenizer=tokenizer)\n",
    "# piecewise_length = chat_tokenizer.tokenize_piecewise(templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4096, 4096])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.layers[0].self_attn.q_proj.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1217, device='cuda:0') tensor(920, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "q = model.model.layers[16].self_attn.q_proj.weight\n",
    "q.requires_grad = False\n",
    "k = model.model.layers[16].self_attn.k_proj.weight\n",
    "k.requires_grad = False\n",
    "\n",
    "k = torch.repeat_interleave(k, 4, dim=0)\n",
    "u_q, s_q, v_q = torch.svd(q)\n",
    "u_k, s_k, v_k = torch.svd(k)\n",
    "\n",
    "threshold = 1\n",
    "print((s_q > threshold).sum(), (s_k > threshold).sum())\n",
    "\n",
    "s_q[s_q < threshold] = 0\n",
    "s_k[s_k < threshold] = 0\n",
    "\n",
    "embeddings = model.model.embed_tokens.weight\n",
    "embeddings.requires_grad = False\n",
    "\n",
    "u_qk = u_q.T @ u_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.58%\n"
     ]
    }
   ],
   "source": [
    "x = embeddings[tokenizer.encode(\"young\")[-1]]\n",
    "y = embeddings[tokenizer.encode(\"king\")[-1]]\n",
    "\n",
    "x_prime = v_q.T @ x\n",
    "y_prime = v_k.T @ y\n",
    "\n",
    "x_prime = s_q * x_prime\n",
    "y_prime = s_k * y_prime\n",
    "\n",
    "real = (k @ y) @ (q @ x)\n",
    "pred = x_prime @ (u_qk @ y_prime)\n",
    "\n",
    "real = real.item()\n",
    "pred = pred.item()\n",
    "\n",
    "print(f'{abs((real / pred ) - 1) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [07:12<00:00, 13.51s/it]\n"
     ]
    }
   ],
   "source": [
    "qs = []\n",
    "ks = []\n",
    "vs = []\n",
    "os = []\n",
    "\n",
    "for i in trange(32):\n",
    "    q = model.model.layers[i].self_attn.q_proj.weight\n",
    "    q.requires_grad = False\n",
    "    k = model.model.layers[i].self_attn.k_proj.weight\n",
    "    k.requires_grad = False\n",
    "    v = model.model.layers[i].self_attn.v_proj.weight\n",
    "    v.requires_grad = False\n",
    "    o = model.model.layers[i].self_attn.o_proj.weight\n",
    "    o.requires_grad = False\n",
    "\n",
    "    k = torch.repeat_interleave(k, 4, dim=0)\n",
    "    v = torch.repeat_interleave(v, 4, dim=0)\n",
    "\n",
    "    u_q, s_q, v_q = torch.svd(q)\n",
    "    u_k, s_k, v_k = torch.svd(k)\n",
    "    u_v, s_v, v_v = torch.svd(v)\n",
    "    u_o, s_o, v_o = torch.svd(o)\n",
    "\n",
    "    threshold = 1\n",
    "    qs.append(u_q[:torch.sum(s_q > threshold)])\n",
    "    ks.append(u_k[:torch.sum(s_k > threshold)])\n",
    "    vs.append(u_v[:torch.sum(s_v > threshold)])\n",
    "    os.append(u_o[:torch.sum(s_o > threshold)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing Layer 3 with Layer 10\n",
      "Similarity of QO Matrix\n",
      "763 87\n",
      "634 87\n",
      "Max Similarity: 0.15, Min Similarity: -0.22\n",
      "Comparing Layer 4 with Layer 6\n",
      "Similarity of QO Matrix\n",
      "250 87\n",
      "184 87\n",
      "Max Similarity: 0.23, Min Similarity: -0.17\n",
      "Comparing Layer 4 with Layer 7\n",
      "Similarity of QO Matrix\n",
      "184 212\n",
      "251 212\n",
      "Max Similarity: 0.16, Min Similarity: -0.21\n",
      "Comparing Layer 4 with Layer 12\n",
      "Similarity of QO Matrix\n",
      "123 212\n",
      "1148 87\n",
      "Max Similarity: 0.13, Min Similarity: -0.21\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "j = 0\n",
    "\n",
    "for i in range(32):\n",
    "    for j in range(32):\n",
    "        sim1 = qs[i] @ ks[j].T\n",
    "        sim2 = qs[i] @ vs[j].T\n",
    "        sim3 = qs[i] @ os[j].T\n",
    "        sim4 = ks[i] @ vs[j].T\n",
    "        sim5 = ks[i] @ os[j].T\n",
    "        sim6 = vs[i] @ os[j].T\n",
    "        for sim, name in zip([sim1, sim2, sim3, sim4, sim5, sim6], [\"QK\", \"QV\", \"QO\", \"KV\", \"KO\", \"VO\"]):\n",
    "            max_sim = torch.max(sim).item()\n",
    "            min_sim = torch.min(sim).item()\n",
    "            if max_sim > 0.2 or min_sim < -0.2:\n",
    "                print(f\"Comparing Layer {i} with Layer {j}\")\n",
    "                print(f\"Similarity of {name} Matrix\")\n",
    "                max_index = torch.argmax(sim).item()\n",
    "                min_index = torch.argmin(sim).item()\n",
    "                print(max_index // sim.shape[1], max_index % sim.shape[1])\n",
    "                print(min_index // sim.shape[1], min_index % sim.shape[1])\n",
    "                print(f\"Max Similarity: {max_sim:.2f}, Min Similarity: {min_sim:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_q = torch.cat(qs, dim=0)\n",
    "flat_k = torch.cat(ks, dim=0)\n",
    "flat_v = torch.cat(vs, dim=0)\n",
    "flat_o = torch.cat(os, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matrices = torch.cat([flat_q, flat_k, flat_v, flat_o], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matrices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1\n",
    "cutoff = 1\n",
    "\n",
    "q_dim_counts = []\n",
    "k_dim_counts = []\n",
    "\n",
    "for index in range(layer_count):\n",
    "    q_proj = model.model.layers[index].self_attn.q_proj.weight\n",
    "    q_proj.requires_grad = False\n",
    "    U, S, V = torch.svd(q_proj)\n",
    "    dim_count = (S > cutoff).sum().item()\n",
    "    q_dim_counts.append(dim_count)\n",
    "    print(f\"Q {index}\", dim_count)\n",
    "\n",
    "    k_proj = model.model.layers[index].self_attn.k_proj.weight\n",
    "    k_proj.requires_grad = False\n",
    "    k_proj = torch.repeat_interleave(k_proj, 4, dim=0)\n",
    "    U, S, V = torch.svd(k_proj)\n",
    "    c = S[0] * cutoff\n",
    "    dim_count = (S > cutoff).sum().item()\n",
    "    k_dim_counts.append(dim_count)\n",
    "    print(f\"K {index}\", dim_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(q_dim_counts, label=\"Q\")\n",
    "plt.plot(k_dim_counts, label=\"K\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.title(\"Q and K Dimension Counts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.model.layers:\n",
    "    layer.self_attn.attention_dropout = 0.1\n",
    "    layer.self_attn.training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, trange\n",
    "\n",
    "data_per_paragraph = 50\n",
    "paragraph_index = 417\n",
    "\n",
    "prompt = templates.format(paragraph=dataset[paragraph_index])\n",
    "input_ids = chat_tokenizer.tokenize_prompt(prompt, add_generation_prompt=False).cuda()\n",
    "input_length = len(input_ids[0])\n",
    "\n",
    "collected_data = torch.zeros((data_per_paragraph, layer_count+1, input_length, dim)).cuda()\n",
    "\n",
    "model.train()\n",
    "with torch.no_grad():\n",
    "    for i in trange(data_per_paragraph):\n",
    "        output = model(input_ids=input_ids, output_hidden_states=True).hidden_states\n",
    "        output = torch.stack(output).squeeze(1)\n",
    "        collected_data[i] = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collected_data = collected_data.transpose(0, 1).reshape(layer_count+1, -1, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model.model.layers[0].self_attn.q_proj.weight\n",
    "U, S, V = torch.svd(a)\n",
    "U[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collected_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collected_data = collected_data / collected_data.norm(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_size = min(collected_data.shape[1], dim)\n",
    "\n",
    "# Us = torch.zeros((layer_count+1, dim, dim)).cuda()\n",
    "Ss = torch.zeros((layer_count+1, dim)).cuda()\n",
    "# Vs = torch.zeros((layer_count+1, collected_data.shape[1], dim)).cuda()\n",
    "\n",
    "for i in trange(layer_count+1):\n",
    "    S = torch.linalg.svdvals(collected_data[i])\n",
    "    Ss[i] = S\n",
    "\n",
    "    # U, S, V = torch.svd(collected_data[i].T)\n",
    "    # Us[i] = U\n",
    "    # Ss[i] = S\n",
    "    # Vs[i] = V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_cumsums = torch.cumsum(Ss, -1) / Ss.sum(-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 100\n",
    "plt.plot(S_cumsums[:, index].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.8\n",
    "threshold_indices = []\n",
    "for layer in S_cumsums:\n",
    "    threshold_indices.append(torch.where(layer > threshold)[0][0].item())\n",
    "plt.plot(threshold_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.model.layers:\n",
    "    layer.self_attn.attention_dropout = 0\n",
    "    layer.self_attn.training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_count = 3000\n",
    "record_indices_count = 25\n",
    "hidden_states = torch.zeros((layer_count, input_data_count, record_indices_count, dim), device='cpu', dtype=torch.float32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in trange(input_data_count):\n",
    "        # prompt = templates.format(paragraph=dataset[i])\n",
    "        # input_ids = chat_tokenizer.tokenize_prompt(prompt, add_generation_prompt=False).cuda()\n",
    "        # <|begin_of_text|>\n",
    "        prompt = f\"\"\"Summarize the following paragraph: \\n\\\"\\\"\\\"\\n{dataset[i]}\\n\\\"\\\"\\\"\\nThe paragraph is about \"\"\"\n",
    "        input_ids = tokenizer(prompt, return_tensors='pt').input_ids.cuda()\n",
    "        # input_ids = input_ids[:, :-1]\n",
    "        output = model(input_ids=input_ids, output_hidden_states=True).hidden_states[1:]\n",
    "        # first layer -> word emb + pos emb\n",
    "        # second layer -> layer 1 ....\n",
    "        output = torch.stack(output).squeeze(1)\n",
    "        hidden_states[:, i, :, :] = output[:, -record_indices_count:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden_states /= hidden_states.norm(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncated_size = 3000\n",
    "Ss_cumsums = torch.zeros((layer_count, record_indices_count, truncated_size), device=model.device)\n",
    "\n",
    "with tqdm(total=layer_count * record_indices_count) as pbar:\n",
    "    for i in range(layer_count):\n",
    "        hidden_states_layer = hidden_states[i].cuda().to(torch.float32)\n",
    "        for j in range(record_indices_count):\n",
    "            layer = hidden_states_layer[:, j]\n",
    "            layer = layer - layer.mean(0)\n",
    "            S = torch.linalg.svdvals(layer, driver='gesvdj')\n",
    "            S_cumsums = torch.cumsum(S[:truncated_size], -1) / S.sum()\n",
    "            Ss_cumsums[i][j] = S_cumsums\n",
    "\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ss_cumsums.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly import express as px\n",
    "import pandas as pd\n",
    "\n",
    "threshold = 0.9\n",
    "\n",
    "\n",
    "# df = pd.DataFrame(cum_sums)\n",
    "\n",
    "# cum_sums = {record_indices_count-i: list(Ss_cumsums[:, i, 999].cpu().numpy()) for i in range( record_indices_count)}\n",
    "\n",
    "cum_sums = {}\n",
    "for i in range(10, record_indices_count):\n",
    "    # cum_sums[record_indices_count - i] = Ss_cumsums[:, i, 299].cpu().numpy()\n",
    "    # plt.plot(Ss_cumsums[:, i, 299].cpu().numpy(), label=i)\n",
    "\n",
    "\n",
    "    # fig = px.line(x=np.arange(layer_count), y=Ss_cumsums[:, i, 299].cpu().numpy(), title=f\"Record Index: {i}\")\n",
    "    threshold_indices = []\n",
    "    for layer in Ss_cumsums[:, i]:\n",
    "        threshold_indices.append(torch.where(layer > threshold)[0][0].item())\n",
    "    cum_sums[record_indices_count - i] = threshold_indices\n",
    "    # plt.plot(threshold_indices, label=i)\n",
    "\n",
    "px.line(cum_sums, title=\"Cumulative Sum of Singular Values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.decode(input_ids[0][-13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "input_data_count = 150\n",
    "total_sequence_length = 3000\n",
    "hidden_states = torch.zeros((layer_count, total_sequence_length, dim)).to(model.device)\n",
    "first_hidden_states = torch.zeros((layer_count, input_data_count, dim)).to(model.device)\n",
    "\n",
    "pointer = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    with tqdm(total=total_sequence_length) as pbar:\n",
    "        for i in range(input_data_count):\n",
    "            prompt = templates.format(paragraph=dataset[i])\n",
    "            input_ids = chat_tokenizer.tokenize_prompt(prompt, add_generation_prompt=False).cuda()\n",
    "            input_length = len(input_ids[0])\n",
    "            if pointer+input_length >= total_sequence_length:\n",
    "                break\n",
    "\n",
    "            output = model(input_ids=input_ids, output_hidden_states=True).hidden_states[1:]\n",
    "            # first layer -> word emb + pos emb\n",
    "            # second layer -> layer 1 ....\n",
    "            output = torch.stack(output).squeeze(1)\n",
    "\n",
    "            hidden_states[:, pointer:pointer+input_length, :] = output\n",
    "            first_hidden_states[:, i, :] = output[:, 0, :]\n",
    "\n",
    "            pointer += input_length\n",
    "            pbar.update(input_length)\n",
    "\n",
    "hidden_states = hidden_states[:, :pointer, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model._modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "threshold = 0.95\n",
    "Ss = torch.zeros((layer_count, dim))\n",
    "\n",
    "for i in trange(layer_count):\n",
    "    h = hidden_states[i]\n",
    "    h -= h.mean(0)\n",
    "    U, S, V = torch.svd(h)\n",
    "    Ss[i] = S / S.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(torch.sum(Ss[:, :10], dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets\n",
    "\n",
    "slider = widgets.IntSlider(min=0, max=300, description=\"components\")\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "def plot(components):\n",
    "    plt.plot(np.sum(subspace_variance[:, :components], axis=-1))\n",
    "\n",
    "interact(plot, components=slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "separators = [',', '.', '!', '?', ';', ':', '\\n', '\"', \"'\", '(', ')', '[', ']', '{', '}', ' ,', ' .', ' !', ' ?', ' ;', ' :', ' \\n', ' \"', ' \\'', ' (', ' )', ' [', ' ]', ' {', ' }', '.\\n', '\\n\\n', ':\\n']\n",
    "separator_tokens = [tokenizer.encode(separator)[1] for separator in separators]\n",
    "\n",
    "# separator_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ChatTemplates(templates=[\n",
    "    SystemTemplate(template=\"You are the user's friend\"),\n",
    "    UserTemplate(template=\"Hey man\"),\n",
    "    AssistantTemplate(template=\"Hey! How's it going?\"),\n",
    "    UserTemplate(template=\"It's going good, anything interesting\"),\n",
    "    AssistantTemplate(template=\"Not much, just hanging out. What about you? Any plans for today?\"),\n",
    "    UserTemplate(template=\"Not really, just some coding\"),\n",
    "    AssistantTemplate(template=\"Nice! What are you working on?\"),\n",
    "    UserTemplate(template=\"Working on some ai side projects of mine, what about u\"),\n",
    "    AssistantTemplate(template=\"Just finished reading this wild sci-fi novel about AI taking over Mars. Really got me thinking.\"),\n",
    "    UserTemplate(template=\"Oh cool cool.\"),\n",
    "    AssistantTemplate(template=\"Been watching any good shows or movies lately?\"),\n",
    "    UserTemplate(template=\"Yeah I like the three body problem series\"),\n",
    "    AssistantTemplate(template=\"I've heard of that! What's it about?\"),\n",
    "    UserTemplate(template=\"It's about a first contact scenario with an alien civilization\"),\n",
    "])\n",
    "\n",
    "\n",
    "prompt = conversation.format()\n",
    "input_ids = chat_tokenizer.tokenize_prompt(prompt, add_generation_prompt=False)\n",
    "separator_indices = np.isin(input_ids, separator_tokens).nonzero()[1]\n",
    "\n",
    "for i in range(len(separator_indices)):\n",
    "    if i == 0:\n",
    "        start = 0\n",
    "    else:\n",
    "        start = separator_indices[i-1]\n",
    "    end = separator_indices[i]\n",
    "    print(repr(tokenizer.decode(input_ids[0][start+1:end+1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(input_ids=input_ids, output_attentions=True, output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1,2,3,4,7], dtype=torch.float32)\n",
    "a -= a.mean()\n",
    "\n",
    "var = a.pow(2).mean()\n",
    "std1 = torch.rsqrt(var) / (a.numel() ** 0.5)\n",
    "# length\n",
    "# var3 = torch.norm(a) ** 2 / a.numel()\n",
    "std2 = 1 / torch.norm(a)\n",
    "\n",
    "std1, std2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = []\n",
    "norms = []\n",
    "\n",
    "for i in range(33):\n",
    "    means.append(torch.mean(output.hidden_states[i][0]).item())\n",
    "    norms.append(torch.mean(torch.norm(output.hidden_states[i][0], dim=-1)).item())\n",
    "\n",
    "plt.plot(means)\n",
    "plt.plot(norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, trange\n",
    "\n",
    "for paragraph_index in tqdm(top_indices):\n",
    "    paragraph_index = 0\n",
    "    with torch.no_grad():\n",
    "        # prompt = templates.format(paragraph=paragraph)\n",
    "        propmt = conversation.format()\n",
    "        input_ids = chat_tokenizer.tokenize_prompt(prompt, add_generation_prompt=False)\n",
    "        output = model(input_ids=input_ids, output_attentions=True)\n",
    "\n",
    "    separator_indices = np.isin(input_ids, separator_tokens).nonzero()[1]\n",
    "    size = len(separator_indices) + 1\n",
    "    total_size = len(input_ids[0])\n",
    "\n",
    "    separator_lengths = np.diff(separator_indices, prepend=0, append=total_size)\n",
    "\n",
    "    # x axis: layers\n",
    "    # y axis: head\n",
    "\n",
    "    layered_block_attention = np.zeros((32, 32, size, size))\n",
    "    for layer in range(32):\n",
    "        output_attentions = output.attentions[layer][0]\n",
    "        block_attentions = []\n",
    "\n",
    "        for head in range(32):\n",
    "            # block_attention = np.zeros((len(separator_indices) + 1, len(separator_indices) + 1))\n",
    "            attention = output_attentions[head]\n",
    "            # attention = torch.log(attention)\n",
    "            attention = attention[1:, 1:]\n",
    "            attention = attention.cpu().numpy()\n",
    "            # split the attention matrix into impulse blocks\n",
    "            for i, row in enumerate(np.split(attention, separator_indices, axis=0)):\n",
    "                for j, block in enumerate(np.split(row, separator_indices, axis=1)):\n",
    "                    # block_attention[i, j] = block.mean()\n",
    "                    block = block[1:, 1:]\n",
    "                    if block.size == 0:\n",
    "                        # block_attention[i, j] = -10\n",
    "                        layered_block_attention[layer, head, i, j] = -13\n",
    "                        continue\n",
    "                    # block_attention[i, j] = np.log(block.mean())\n",
    "                    layered_block_attention[layer, head, i, j] = np.log(block.mean() + 1e-14)\n",
    "\n",
    "    # repeat layers for ith layer with the amount of times listed in separator length[i]\n",
    "    layered_block_attention = np.repeat(layered_block_attention, separator_lengths, axis=2)\n",
    "    layered_block_attention = np.repeat(layered_block_attention, separator_lengths, axis=3)\n",
    "\n",
    "    mean_layered_block_attention = np.mean(layered_block_attention, axis = 1)\n",
    "    std_layered_block_attention = np.std(layered_block_attention, axis = 1)\n",
    "\n",
    "    mean_high = np.quantile(mean_layered_block_attention, 0.95)\n",
    "    mean_low = np.quantile(mean_layered_block_attention, 0.05)\n",
    "\n",
    "    std_high = np.quantile(std_layered_block_attention, 0.95)\n",
    "    std_low = np.quantile(std_layered_block_attention, 0.05)\n",
    "\n",
    "    mean_layered_block_attention = np.clip(mean_layered_block_attention, mean_low, mean_high)\n",
    "    std_layered_block_attention = np.clip(std_layered_block_attention, std_low, std_high)\n",
    "\n",
    "    print(mean_high, mean_low, std_high, std_low)\n",
    "\n",
    "    # layer * i * j\n",
    "    mean_block_attention = mean_layered_block_attention.reshape(32 * total_size, total_size)\n",
    "    std_block_attention = std_layered_block_attention.reshape(32 * total_size, total_size)\n",
    "\n",
    "    plt.imsave(f'figures/{paragraph_index}_mean.png', arr=mean_block_attention, cmap='crest', format='png')\n",
    "    plt.imsave(f'figures/{paragraph_index}_std.png', arr=std_block_attention, cmap='crest', format='png')\n",
    "\n",
    "    # layer * head * i * j\n",
    "    # diff_layered_block_attention = np.diff(layered_block_attention, axis=1)\n",
    "\n",
    "    # low = -5\n",
    "    # high = 5\n",
    "    # diff_layered_block_attention = (diff_layered_block_attention - low) / (high - low)\n",
    "    # diff_layered_block_attention = np.clip(diff_layered_block_attention, 0, 1)\n",
    "    # # (layer * i) * (head * j)\n",
    "    # # x axis: layer and i\n",
    "    # # y axis: head and j\n",
    "\n",
    "    # block_attentions = diff_layered_block_attention.transpose(0, 2, 1, 3).reshape(32 * size, 31 * size)\n",
    "\n",
    "    # plt.imsave(f'figures/{paragraph_index}.png', arr=block_attentions, cmap='coolwarm', format='png')\n",
    "\n",
    "    # with open(f'figures/{paragraph_index}.txt', 'w') as f:\n",
    "    #     f.write(dataset[paragraph_index])\n",
    "\n",
    "    low = -13\n",
    "    high = -4.5\n",
    "    # layer * head * block * block\n",
    "    layered_block_attention = np.clip(layered_block_attention, low, high)\n",
    "    # print(layered_block_attention.shape)\n",
    "    block_attentions = layered_block_attention.transpose(0, 2, 1, 3).reshape(32 * total_size, 32 * total_size)\n",
    "\n",
    "    # plt.imsave(f'figures/{paragraph_index}.png', arr=block_attentions, cmap='viridis',format='png')\n",
    "\n",
    "    plt.imsave(f'figures/{paragraph_index}.png', arr=block_attentions, cmap='crest', format='png')\n",
    "\n",
    "    with open(f'figures/{paragraph_index}.txt', 'w') as f:\n",
    "        f.write(dataset[paragraph_index])\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imsave(\"1.png\", np.random.rand(5, 20), cmap='coolwarm', format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([7,9,10,10.3,10.5])\n",
    "\n",
    "b = np.exp(a) / np.exp(a).sum()\n",
    "\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the colorbar\n",
    "# low -> high\n",
    "# -13 -> -4.5\n",
    "\n",
    "plt.imshow(block_attentions, cmap='viridis')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = templates.format(paragraph=dataset[975])\n",
    "input_ids = chat_tokenizer.tokenize_prompt(prompt, add_generation_prompt=False)\n",
    "separator_indices = [i for i, token in enumerate(input_ids[0]) if token in separator_tokens]\n",
    "\n",
    "for i in range(1, len(separator_indices)):\n",
    "    slice = input_ids[0][separator_indices[i-1]:separator_indices[i]]\n",
    "    print(repr(tokenizer.decode(slice[1:])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
