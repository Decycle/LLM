{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "model_name = 'meta-llama/Llama-2-7b-hf'\n",
    "# model_name = 'princeton-nlp/unsup-simcse-roberta-large'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, token=\"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\")\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, token=\"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\")\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"lukaemon/mmlu\", 'high_school_world_history', split='test')\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"<s>[INST] <<SYS>>\n",
    "Answer the following question\n",
    "<</SYS>>\n",
    "{input}\n",
    "A. {A}\n",
    "B. {B}\n",
    "C. {C}\n",
    "D. {D}[/INST]\n",
    "The answer is:\"\"\"\n",
    "\n",
    "dataset = dataset.map(lambda x: {'text':template.format(**x)})\n",
    "dataset = dataset.map(lambda x: tokenizer(x['text'], return_tensors='pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_count = 20\n",
    "max_length = 350\n",
    "\n",
    "filtered_dataset = dataset.filter(lambda x: len(x['input_ids'][0]) <= max_length)\n",
    "# raw_layers_data = torch.zeros(data_count, 33, max_length, 4096).to(device)\n",
    "raw_layers_data = np.zeros((data_count, 33, max_length, 4096), dtype=np.float32)\n",
    "# tokens_mask = torch.zeros(data_count, max_length, dtype=torch.int32).to(device)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for i, row in tqdm(enumerate(filtered_dataset), total=data_count):\n",
    "#         if i >= data_count:\n",
    "#             break\n",
    "#         input_ids = torch.tensor(row['input_ids']).to(device)\n",
    "#         output = model(input_ids=input_ids,output_hidden_states=True)\n",
    "#         hidden_states = torch.stack(output.hidden_states).squeeze(1)\n",
    "#         raw_layers_data[i, :, :hidden_states.shape[1], :] = hidden_states\n",
    "#         tokens_mask[i, :hidden_states.shape[1]] = 1\n",
    "\n",
    "# print(raw_layers_data.shape)\n",
    "# print(tokens_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_length = tokens_mask.sum(axis=-1)\n",
    "tokens_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qrpca.qrpca.decomposition import qrpca\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "dim = 3\n",
    "pca = qrpca(3, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from qrpca.decomposition import qrpca\n",
    "\n",
    "# dim = 3\n",
    "# pca = PCA(n_components=dim)\n",
    "\n",
    "# flatten all\n",
    "# expanded_tokens_mask = tokens_mask[:, None, :, None]\n",
    "# expanded_tokens_mask = expanded_tokens_mask.repeat(1, 33, 1, 4096)\n",
    "\n",
    "# flattened_data = raw_layers_data[expanded_tokens_mask == 1].view(-1, 4096)\n",
    "# flattened_data /= torch.norm(flattened_data, dim=1, keepdim=True)\n",
    "# layers_2d = pca.fit_transform(flattened_data)\n",
    "# layers_2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/33 [00:00<?, ?it/s]/workspace/attention_analysis/qrpca/qrpca/decomposition.py:106: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "/workspace/attention_analysis/qrpca/qrpca/decomposition.py:173: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "  3%|▎         | 1/33 [00:06<03:32,  6.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0502, 0.0460, 0.0336], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 2/33 [00:09<02:18,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0145, device='cuda:0')\n",
      "tensor(0.1098, device='cuda:0')\n",
      "tensor(-0.0358, device='cuda:0')\n",
      "tensor([0.1061, 0.0364, 0.0212], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 3/33 [00:12<01:51,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8448, device='cuda:0')\n",
      "tensor(0.6633, device='cuda:0')\n",
      "tensor(0.7806, device='cuda:0')\n",
      "tensor([0.0758, 0.0407, 0.0319], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 4/33 [00:15<01:36,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.9614, device='cuda:0')\n",
      "tensor(0.9359, device='cuda:0')\n",
      "tensor(0.8550, device='cuda:0')\n",
      "tensor([0.0549, 0.0334, 0.0269], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 5/33 [00:17<01:27,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.9252, device='cuda:0')\n",
      "tensor(0.7629, device='cuda:0')\n",
      "tensor(-0.6525, device='cuda:0')\n",
      "tensor([0.0450, 0.0295, 0.0254], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 6/33 [00:20<01:21,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.9281, device='cuda:0')\n",
      "tensor(0.8140, device='cuda:0')\n",
      "tensor(0.5299, device='cuda:0')\n",
      "tensor([0.0367, 0.0299, 0.0210], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 7/33 [00:23<01:16,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2985, device='cuda:0')\n",
      "tensor(0.2717, device='cuda:0')\n",
      "tensor(0.8917, device='cuda:0')\n",
      "tensor([0.0291, 0.0289, 0.0195], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 8/33 [00:26<01:11,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.7281, device='cuda:0')\n",
      "tensor(0.8663, device='cuda:0')\n",
      "tensor(0.6940, device='cuda:0')\n",
      "tensor([0.0351, 0.0259, 0.0182], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 9/33 [00:28<01:07,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.8743, device='cuda:0')\n",
      "tensor(0.9166, device='cuda:0')\n",
      "tensor(-0.8566, device='cuda:0')\n",
      "tensor([0.0359, 0.0226, 0.0200], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 10/33 [00:31<01:04,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8837, device='cuda:0')\n",
      "tensor(-0.8833, device='cuda:0')\n",
      "tensor(0.8238, device='cuda:0')\n",
      "tensor([0.0389, 0.0219, 0.0182], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 11/33 [00:34<01:01,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.8924, device='cuda:0')\n",
      "tensor(0.8906, device='cuda:0')\n",
      "tensor(-0.8596, device='cuda:0')\n",
      "tensor([0.0377, 0.0215, 0.0189], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 12/33 [00:37<00:58,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.8971, device='cuda:0')\n",
      "tensor(0.8338, device='cuda:0')\n",
      "tensor(-0.9070, device='cuda:0')\n",
      "tensor([0.0396, 0.0218, 0.0190], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 13/33 [00:40<00:55,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.9192, device='cuda:0')\n",
      "tensor(0.8959, device='cuda:0')\n",
      "tensor(0.9445, device='cuda:0')\n",
      "tensor([0.0413, 0.0225, 0.0186], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 14/33 [00:42<00:52,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9325, device='cuda:0')\n",
      "tensor(-0.8978, device='cuda:0')\n",
      "tensor(-0.8142, device='cuda:0')\n",
      "tensor([0.0385, 0.0209, 0.0188], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 15/33 [00:45<00:50,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.9119, device='cuda:0')\n",
      "tensor(-0.8523, device='cuda:0')\n",
      "tensor(-0.8795, device='cuda:0')\n",
      "tensor([0.0416, 0.0219, 0.0203], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 16/33 [00:48<00:47,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.9400, device='cuda:0')\n",
      "tensor(-0.6926, device='cuda:0')\n",
      "tensor(0.6952, device='cuda:0')\n",
      "tensor([0.0391, 0.0214, 0.0199], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 17/33 [00:51<00:44,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.9361, device='cuda:0')\n",
      "tensor(-0.9334, device='cuda:0')\n",
      "tensor(-0.9059, device='cuda:0')\n",
      "tensor([0.0402, 0.0199, 0.0191], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 18/33 [00:53<00:41,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.9340, device='cuda:0')\n",
      "tensor(-0.5949, device='cuda:0')\n",
      "tensor(0.5272, device='cuda:0')\n",
      "tensor([0.0398, 0.0214, 0.0196], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 19/33 [00:56<00:38,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9320, device='cuda:0')\n",
      "tensor(0.9432, device='cuda:0')\n",
      "tensor(0.9271, device='cuda:0')\n",
      "tensor([0.0406, 0.0233, 0.0183], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 20/33 [00:59<00:36,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9464, device='cuda:0')\n",
      "tensor(-0.9782, device='cuda:0')\n",
      "tensor(-0.9445, device='cuda:0')\n",
      "tensor([0.0420, 0.0238, 0.0185], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 21/33 [01:02<00:33,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9689, device='cuda:0')\n",
      "tensor(-0.9767, device='cuda:0')\n",
      "tensor(-0.9608, device='cuda:0')\n",
      "tensor([0.0392, 0.0256, 0.0180], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 22/33 [01:05<00:30,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.9432, device='cuda:0')\n",
      "tensor(-0.9502, device='cuda:0')\n",
      "tensor(-0.8825, device='cuda:0')\n",
      "tensor([0.0377, 0.0259, 0.0191], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 23/33 [01:07<00:27,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9634, device='cuda:0')\n",
      "tensor(-0.9767, device='cuda:0')\n",
      "tensor(0.9663, device='cuda:0')\n",
      "tensor([0.0370, 0.0258, 0.0190], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 24/33 [01:10<00:24,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9366, device='cuda:0')\n",
      "tensor(-0.9428, device='cuda:0')\n",
      "tensor(0.9554, device='cuda:0')\n",
      "tensor([0.0372, 0.0285, 0.0186], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 25/33 [01:13<00:22,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9773, device='cuda:0')\n",
      "tensor(-0.9801, device='cuda:0')\n",
      "tensor(0.9797, device='cuda:0')\n",
      "tensor([0.0375, 0.0260, 0.0178], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 26/33 [01:16<00:19,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.9730, device='cuda:0')\n",
      "tensor(-0.9675, device='cuda:0')\n",
      "tensor(-0.9591, device='cuda:0')\n",
      "tensor([0.0415, 0.0260, 0.0186], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 27/33 [01:18<00:16,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.9865, device='cuda:0')\n",
      "tensor(0.9820, device='cuda:0')\n",
      "tensor(0.9806, device='cuda:0')\n",
      "tensor([0.0399, 0.0246, 0.0183], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 28/33 [01:21<00:13,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.9774, device='cuda:0')\n",
      "tensor(-0.9677, device='cuda:0')\n",
      "tensor(-0.9727, device='cuda:0')\n",
      "tensor([0.0424, 0.0257, 0.0178], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 29/33 [01:24<00:11,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.9925, device='cuda:0')\n",
      "tensor(0.9855, device='cuda:0')\n",
      "tensor(-0.9712, device='cuda:0')\n",
      "tensor([0.0410, 0.0252, 0.0173], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 30/33 [01:27<00:08,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.9910, device='cuda:0')\n",
      "tensor(-0.9795, device='cuda:0')\n",
      "tensor(-0.8966, device='cuda:0')\n",
      "tensor([0.0391, 0.0270, 0.0172], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 31/33 [01:30<00:05,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.9804, device='cuda:0')\n",
      "tensor(0.9663, device='cuda:0')\n",
      "tensor(0.9165, device='cuda:0')\n",
      "tensor([0.0374, 0.0296, 0.0184], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 32/33 [01:32<00:02,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.7583, device='cuda:0')\n",
      "tensor(-0.7354, device='cuda:0')\n",
      "tensor(-0.8114, device='cuda:0')\n",
      "tensor([0.0409, 0.0293, 0.0222], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [01:35<00:00,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.4544, device='cuda:0')\n",
      "tensor(0.2124, device='cuda:0')\n",
      "tensor(0.0131, device='cuda:0')\n",
      "tensor([0.1912, 0.0842, 0.0478], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 33, 350, 3])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#flatten each layer\n",
    "layers_2d = torch.zeros((raw_layers_data.shape[0], 33, raw_layers_data.shape[2], dim)).to(device)\n",
    "\n",
    "last_comp = None\n",
    "for i in tqdm(range(33)):\n",
    "    layer = raw_layers_data[:, i]\n",
    "    layer /= torch.norm(layer, dim=-1, keepdim=True)\n",
    "    expanded_tokens_mask = tokens_mask.unsqueeze(-1).expand(-1, -1, 4096)\n",
    "    flattened_data = layer[expanded_tokens_mask == 1].view(-1, 4096)\n",
    "    pca.fit(flattened_data)\n",
    "    comp = pca._qrpca__Vt[:dim]\n",
    "    if last_comp is not None:\n",
    "        # make sure the new components are not flipped\n",
    "        for j in range(dim):\n",
    "            dot_product = torch.dot(comp[j], last_comp[j])\n",
    "            if dot_product < 0:\n",
    "                comp[j] *= -1\n",
    "            print(dot_product)\n",
    "    pca._qrpca__Vt[:dim] = comp\n",
    "    flattened_data_2d = pca.transform(flattened_data)\n",
    "    data = torch.zeros(layer.shape[0], layer.shape[1], dim)\n",
    "    expanded_tokens_mask = tokens_mask.unsqueeze(-1).expand(-1, -1, dim)\n",
    "    data[expanded_tokens_mask == 1] = torch.tensor(flattened_data_2d).flatten()\n",
    "    layers_2d[:, i] = data\n",
    "    last_comp = comp\n",
    "    print(pca.explained_variance_ratio)\n",
    "\n",
    "layers_2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import plotly.colors as colors\n",
    "\n",
    "# Create a color gradient\n",
    "\n",
    "layers_2d_cpu = layers_2d.cpu().numpy()\n",
    "color_scale = colors.sample_colorscale(colors.sequential.Rainbow, layers_2d_cpu.shape[1])[::-1]\n",
    "\n",
    "data = []\n",
    "\n",
    "for i in range(layers_2d_cpu.shape[0]):\n",
    "    for frame, layer in enumerate(layers_2d_cpu[i]):\n",
    "        for j in range(layers_2d_cpu.shape[2]):\n",
    "            x = layer[j, 0]\n",
    "            y = layer[j, 1]\n",
    "            size = 8 if j == tokens_length[i] - 1 else 1\n",
    "            new_data = {\n",
    "                'x': x,\n",
    "                'y': y,\n",
    "                'frame': frame,\n",
    "                'index': j,\n",
    "                'paragraph': i,\n",
    "                'size': size\n",
    "            }\n",
    "            if dim == 3:\n",
    "                new_data['z'] = layer[j, 2]\n",
    "            data.append(new_data)\n",
    "\n",
    "if dim == 2:\n",
    "    fig = px.scatter(\n",
    "        data_frame=data,\n",
    "        x='x', y='y',\n",
    "        animation_frame='frame',\n",
    "        size='size',\n",
    "        size_max=5,\n",
    "        color_continuous_scale=color_scale,\n",
    "        color='index',\n",
    "        range_x=[-1, 1],\n",
    "        range_y=[-1, 1],\n",
    "        hover_name='index',\n",
    "        hover_data={'paragraph': True},\n",
    "    )\n",
    "    # marker.line.width\n",
    "    fig.update_traces(marker=dict(line=dict(width=0)))\n",
    "    fig.update_layout(\n",
    "        width=600,\n",
    "        height=600,\n",
    "    )\n",
    "else:\n",
    "    fig = px.scatter_3d(\n",
    "        data_frame=data,\n",
    "        x='x', y='y', z='z',\n",
    "        animation_frame='frame',\n",
    "        size='size',\n",
    "        size_max=5,\n",
    "        color_continuous_scale=color_scale,\n",
    "        color='index',\n",
    "        range_x=[-1, 1],\n",
    "        range_y=[-1, 1],\n",
    "        range_z=[-1, 1],\n",
    "        hover_name='index',\n",
    "        hover_data={'paragraph': True},\n",
    "    )\n",
    "    fig.update_traces(marker=dict(line=dict(width=0)))\n",
    "    zoom=0.5\n",
    "    fig.update_layout(\n",
    "        width=600,\n",
    "        height=600,\n",
    "        margin=dict(l=0, r=0, b=0, t=0),\n",
    "        scene=dict(aspectmode='cube',camera=dict(eye=dict(x=zoom, y=zoom, z=zoom)))\n",
    "    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer.encode(sample_text, return_tensors='pt').to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_ids=input_ids, output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids = torch.topk(output.logits[0][-1], 10).indices\n",
    "\n",
    "# for i in ids:\n",
    "#     print(tokenizer.decode(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attentions = output.attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attentions[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's visualize a few of the attention matrices\n",
    "import seaborn as sns\n",
    "\n",
    "fig, axs = plt.subplots(4, 8, figsize=(20, 10))\n",
    "\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    new_attention = attentions[-1][0][i]\n",
    "    sns.heatmap(np.log(new_attention.cpu().numpy() + 1e-10), ax=ax, vmin=-6, vmax=0, cmap='viridis', cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's visualize a few of the attention matrices\n",
    "import plotly.express as px\n",
    "\n",
    "# plot new_attention[-1] with tokens\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids[0])[2:]\n",
    "tokens = [f'{t}{i}' for i, t in enumerate(tokens)]\n",
    "\n",
    "layers = list(range(32))\n",
    "all_attentions = attentions[-1][0, :, -1].cpu().numpy()\n",
    "\n",
    "fig = px.imshow(np.log(all_attentions[:, 2:]), labels=dict(x=\"Layers\", y=\"Tokens\", color=\"Attention\"), x=tokens, y=layers, color_continuous_scale='viridis', zmin=-6)\n",
    "fig.show()\n",
    "# for i, ax in enumerate(axs.flat):\n",
    "#     new_attention = attentions[-1][0][i]\n",
    "#     sns.heatmap(np.log(new_attention.cpu().numpy() + 1e-10), ax=ax, vmin=-6, vmax=0, cmap='viridis', cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# plot new_attention[-1] with tokens\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "tokens = [f'{t}{i}' for i, t in enumerate(tokens)]\n",
    "# tokens = list(range(59))\n",
    "# min = -6, max = 0\n",
    "values = np.log(attentions[-1][0][head].cpu().numpy() + 1e-10)\n",
    "values = np.clip(values, -6, 0) + 6\n",
    "# print(values[21])\n",
    "#\n",
    "fig = px.imshow(values, labels=dict(x=\"Tokens\", y=\"Tokens\", color=\"Attention\"), x=tokens, y=tokens, color_continuous_scale='viridis')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = 15\n",
    "final_attention = attentions[0][0][head]\n",
    "\n",
    "for i in range(1, len(attentions)):\n",
    "    plt.plot(final_attention[-1].cpu().numpy())\n",
    "    final_attention = torch.mm(attentions[i][0][head], final_attention)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
