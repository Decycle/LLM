{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "model_name = 'meta-llama/Llama-2-7b-hf'\n",
    "# model_name = 'princeton-nlp/unsup-simcse-roberta-large'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, token=\"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\")\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, token=\"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\")\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "\n",
    "max_data_count = 200\n",
    "max_length = 512\n",
    "subjects = ['high_school_european_history', 'business_ethics', 'clinical_knowledge', 'medical_genetics', 'high_school_us_history', 'high_school_physics', 'high_school_world_history', 'virology', 'high_school_microeconomics', 'econometrics', 'college_computer_science', 'high_school_biology', 'abstract_algebra', 'professional_accounting', 'philosophy', 'professional_medicine', 'nutrition', 'global_facts', 'machine_learning', 'security_studies', 'public_relations', 'professional_psychology', 'prehistory', 'anatomy', 'human_sexuality', 'college_medicine', 'high_school_government_and_politics', 'college_chemistry', 'logical_fallacies', 'high_school_geography', 'elementary_mathematics', 'human_aging', 'college_mathematics', 'high_school_psychology', 'formal_logic', 'high_school_statistics', 'international_law', 'high_school_mathematics', 'high_school_computer_science', 'conceptual_physics', 'miscellaneous', 'high_school_chemistry', 'marketing', 'professional_law', 'management', 'college_physics', 'jurisprudence', 'world_religions', 'sociology', 'us_foreign_policy', 'high_school_macroeconomics', 'computer_security', 'moral_scenarios', 'moral_disputes', 'electrical_engineering', 'astronomy', 'college_biology']\n",
    "dim = 3\n",
    "\n",
    "pca = PCA(n_components=dim)\n",
    "\n",
    "def process_datasets(subject):\n",
    "    dataset = load_dataset(\"lukaemon/mmlu\", subject, split='test')\n",
    "\n",
    "    template = \"\"\"<s>[INST] <<SYS>>\n",
    "    Answer the following question\n",
    "    <</SYS>>\n",
    "    {input}\n",
    "    A. {A}\n",
    "    B. {B}\n",
    "    C. {C}\n",
    "    D. {D}[/INST]\n",
    "    The answer is:\"\"\"\n",
    "\n",
    "    dataset = dataset.map(lambda x: {'text':template.format(**x)})\n",
    "    dataset = dataset.map(lambda x: tokenizer(x['text'], return_tensors='pt'))\n",
    "\n",
    "    return dataset.filter(lambda x: len(x['input_ids'][0]) <= max_length)\n",
    "\n",
    "def get_hidden_states(dataset):\n",
    "    data_count = min(max_data_count, len(dataset))\n",
    "    raw_layers_data = np.zeros((data_count, 33, max_length, 4096), dtype=np.float32)\n",
    "    tokens_mask = np.zeros((data_count, max_length), dtype=np.int32)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, row in tqdm(enumerate(dataset), total=data_count):\n",
    "            if i >= data_count:\n",
    "                break\n",
    "            input_ids = torch.tensor(row['input_ids']).to(device)\n",
    "            output = model(input_ids=input_ids,output_hidden_states=True)\n",
    "            hidden_states = torch.stack(output.hidden_states).squeeze(1).cpu().numpy()\n",
    "            raw_layers_data[i, :, :hidden_states.shape[1], :] = hidden_states\n",
    "            tokens_mask[i, :hidden_states.shape[1]] = 1\n",
    "\n",
    "    tokens_length = tokens_mask.sum(axis=1)\n",
    "\n",
    "    return raw_layers_data, tokens_mask, tokens_length, data_count\n",
    "\n",
    "def get_3d_data(raw_layers_data, tokens_mask):\n",
    "    layers_3d = np.zeros((raw_layers_data.shape[0], 33, raw_layers_data.shape[2], dim), dtype=np.float32)\n",
    "    pca_components = np.zeros((33, dim, 4096), dtype=np.float32)\n",
    "    variance_ratios = np.zeros((33, dim), dtype=np.float32)\n",
    "\n",
    "    for i in trange(33):\n",
    "        layer = raw_layers_data[:, i]\n",
    "        expanded_tokens_mask = tokens_mask[:, :, np.newaxis]\n",
    "        expanded_tokens_mask = np.broadcast_to(expanded_tokens_mask, layer.shape)\n",
    "        flattened_data = layer[expanded_tokens_mask == 1].reshape(-1, 4096)\n",
    "        flattened_data /= np.linalg.norm(flattened_data, axis=-1, keepdims=True)\n",
    "        pca.fit(flattened_data)\n",
    "        pca_components[i] = pca.components_\n",
    "        if i != 0:\n",
    "            # make sure the new components are not flipped\n",
    "            for j in range(dim):\n",
    "                dot_product = np.dot(pca_components[i, j], pca_components[i-1, j])\n",
    "                if dot_product < 0:\n",
    "                    pca_components[i, j] *= -1\n",
    "        pca.components_ = pca_components[i]\n",
    "        flattened_data_2d = pca.transform(flattened_data)\n",
    "        data = np.zeros((layer.shape[0], layer.shape[1], dim), dtype=np.float32)\n",
    "        expanded_tokens_mask = tokens_mask[:, :, np.newaxis]\n",
    "        expanded_tokens_mask = np.broadcast_to(expanded_tokens_mask, data.shape)\n",
    "        data[expanded_tokens_mask == 1] = flattened_data_2d.flatten()\n",
    "        layers_3d[:, i] = data\n",
    "        variance_ratios[i] = pca.explained_variance_ratio_\n",
    "\n",
    "    return layers_3d, pca_components, variance_ratios\n",
    "\n",
    "def save_file(subject, layers_3d, pca_components, variance_ratios):\n",
    "    if not os.path.exists(subject):\n",
    "        os.mkdir(subject)\n",
    "    np.save(os.path.join(subject, 'layers_3d.npy'), layers_3d)\n",
    "    np.save(os.path.join(subject, 'pca_components.npy'), pca_components)\n",
    "    np.save(os.path.join(subject, 'variance_ratios.npy'), variance_ratios)\n",
    "\n",
    "def process(subject):\n",
    "    print(f\"Processing {subject}\")\n",
    "    print(\"Loading dataset\")\n",
    "    filtered_dataset = process_datasets(subject)\n",
    "    print(\"Passing to decoder\")\n",
    "    raw_layers_data, tokens_mask, tokens_length, data_count = get_hidden_states(filtered_dataset)\n",
    "    print(\"Dimensionality reduction\")\n",
    "    layers_3d, pca_components, variance_ratios = get_3d_data(raw_layers_data, tokens_mask)\n",
    "    print(f\"Saving {subject}\")\n",
    "    save_file(layers_3d, pca_components, variance_ratios)\n",
    "    print(f\"Finished {subject}\")\n",
    "\n",
    "# process(subjects[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dataset = process_datasets(subjects[0])\n",
    "raw_layers_data, tokens_mask, tokens_length, data_count = get_hidden_states(filtered_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_layers_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "similiarities = np.zeros((32, 120, 512))\n",
    "raw_layers_data /= np.linalg.norm(raw_layers_data, axis=-1, keepdims=True) + 1e-8\n",
    "\n",
    "for layer in trange(32):\n",
    "    l0 = raw_layers_data[:, layer]\n",
    "    l1 = raw_layers_data[:, layer + 1]\n",
    "    similiarity = np.einsum('ijk,ijk->ij', l0, l1)\n",
    "    similiarities[layer] = similiarity\n",
    "\n",
    "similiarities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "px.imshow(similiarities, animation_frame=0, zmin=0.5, zmax=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
